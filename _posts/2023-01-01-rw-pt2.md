---
title: Refactoring GitOps repository to support both real-time and reconciliation window changes
layout: post
post-image: "https://raw.githubusercontent.com/MahrRah/mahra.dev/master/assets/images/blog-image_rwpt2.jpg"
description: Restructuring GitOps repository to be able to enable multiple reconciliation types. eg real-time and maintenance window changes with the approach descript in
tags:
  - K8s
  - Flux
  - GitOps
---

<style>
td, th {
   border: none!important;
}
table th:first-of-type {
    width: 10%;
}
table th:nth-of-type(2) {
    width: 10%;
}
t
</style>

**TL;DR: Restructuring GitOps repository to be able to enable multiple reconciliation types. eg real-time and reconciliation window changes with the approach descript in [part 1 of this blog](rw-pt1)**

> If you haven't already read the [first part](rw-pt1), go back and do so, as we will use its approach on how to enable the reconciliation window in this blog.

A more complicated scenario would be if you have some resources that you can only change during a reconciliation window, but there are also some other resources that you want to be able to change in real time.

So our new problem statement is:

_We want to enable two ways of applying changes to a cluster using Flux:_

- _**Real-time changes:** Representing the default behavior of Flux when it comes to reconciling changes._
- _**Reconciliation windows changes:** Predefined time windows in which a change can be applied to the resource by Flux._

We can still use the core approach shown in [part 1 of this series](rw-pt1) to solve our new problem. However, we need to make some small adjustments to how we organize our GitOps repository, to enable real-time as well as reconciliation window changes.

> Note: This approach is true for any two reconciliation types. You can easily replace the real-time changes with a time window, that is different from the one already existing. The restructuring of the GitOps repository would be the same. You only need to add a new set of CronJobs to manage the new windows.

## Core Principles

Before we start restructuring the repository, it might be useful to understand why we have to do so in the first place.
As you saw in the previous blog the granularity of control, we have on when changes get applied to the cluster, stops at the set of resources that are controlled by one `Kustomize` controller.
This means, to be able to control the reconciliation cycle differently for a group of resources, these resources need to be managed by an independent `Kustomize` controller.

So bottom line the goal of the next few sections are:
"Restructure the GitOps repository such that its resources can be managed by one of the N-`Kustomize` controllers we will create.
Where N defined the different ways of applying changes."

Given in this blog we are only interested in real-time and reconciliation window changes, N is equal to 2.

## Set up

### 1. Set up your applications or components

Let's start with the smallest unit of grouping we have in our GitOps repository: `apps`

There are cases where one application has resources that should only change during a reconciliation window, but also some resources that you should have free control over and be able to change in real-time.

Lets look at the example in this sample. Under `apps` we have an `nginx` folder, which contains the deployment, service and a configmap manifest.

<pre><code>
apps
└── nginx
    ├── deployment.yaml
    ├── service.yaml
    └── configmap.yaml
</code></pre>

We want to now make sure we can change the `nginx` server configuration at real-time, but infrasturture changes such as deployment should only change between Monday 8am to Thursday 5pm.

To enable that the first step is to make sure we can split resources that can be changed real-time from resources that can only change state during a reconciliation window from [`kustomizes`](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/) point of view.

> Note: If you are not familiar whith how `kustomize` is used to manage resoruces check out the offical doc from kubernetes on this [Overview of Kustomize](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/)

There are multiple ways to do this.
One would be to keep the existing structure and just remove the reference of resources of one changed type and reference them from another `kustomization.yaml`.
As complicated as this sentence sounds, the more complicated will the GitOps repository eventually become, due to the obscurity of what resource is referenced from where.

Another option is to split all the resoruces for each application we have defined under `apps/` (see [default GitOps folder structure for mono repos](https://fluxcd.io/flux/guides/repository-structure/#repository-structure)) into two versions. These versions' sole purpose is to package the resources to be either managed by the real-time or the reconciliation window `Kustomize` controller.
The advantage of this approach is that there is no need to go find in which `kustomizatin.yaml` resources are referenced to understand if it's managed by the real-time or the reconciliation window `Kustomize` controller.

For maintainability reasons, we will use the second option.

We would split all manifest files into these two subfolders and add the respective suffixes to the subfolders:

- Real-time changes: `-rt`
- Reconciliation windows changes: `-rw`

<table>
<tr>
<th>Origin </th>
<th>Enabeling Realtimeand Reconciliation windows changes </th>
</tr>
<tr>
<td>
  
<pre class="text"><code >
apps
└── nginx
    ├── deployment.yaml
    ├── service.yaml
    └── configmap.yaml
</code></pre>
  
</td>
<td>

<pre class="text"><code >
apps
└── nginx
    ├── nginx-rt
    │   └── configmap.yaml
    └── nginx-rw
        ├── deployment.yaml
        └── service.yaml
</code></pre>

</td>
</tr>
</table>

Result of this you can see in the sample repository [here](https://github.com/MahrRah/flux-maintanance-windows-sample/tree/master/Sample2/apps/nginx)

### 2. Set up your clusters

Now let's put the pieces together and set up the individual cluster directory.

First, to be able to control the cluster with two different `Kustomize` controllers, we need to have two entry points to point the `Kustomize` controller to.
For that we split the previous `apps` into two subfolders, `apps-rt`/`apps-rw`.
Where `./cluster/cluster-1/apps/apps-rt` will be the entry point for the real-time `Kustomize` controller and `./cluster/cluster-1/apps/apps-rw` for the reconciliation window controller.

The folder structure compared side-by-side from before:

<table>
<tr>
<th>Origin </th>
<th>Enabeling Realtimeand Reconciliation windows changes </th>
</tr>
<tr>
<td>

<pre><code>
clusters/edge-01
├── apps
│    └── nginx
└── infra
     └── maintenance-windows
</code></pre>

</td>
<td>

<pre><code>
clusters/cluster-1
├── apps
│   ├── apps-rw
│   │   └── nginx
│   └── apps-rt
│       └── nginx
└── infra
      └── maintenance-windows

</code></pre>

</td>
</tr>
</table>

The next step is to add the `kustomization.yaml` and its correct content to the respective folder.
Let's first have a look at the `clusters/cluster-1/apps` setup.
Both `app-rw` and `app-rt` will have a root `kustomization.yaml` which will point to all applications deployed onto the cluster. In our example, this is only `nginx`.

<table>
<tr>
<th>Folder structure </th>
<th>`kustomization.yaml` of  </th>
</tr>
<tr>
<td>

<pre><code>
clusters/cluster-1
├── apps
│   ├── apps-rw
│   │   ├── kustomization.yaml
│   │   └── nginx
│   └── apps-rt
│       ├── kustomization.yaml
│       └── nginx
└── infra
</code></pre>

</td>
<td>

<pre><code>
#clusters/cluster-1/apps/apps-rw/kustomization.yaml
resources:
  - ./nginx

</code></pre>
<pre><code>
#clusters/cluster-1/apps/apps-rt/kustomization.yaml
resources:
  - ./nginx
</code></pre>

</td>
</tr>
</table>

Both the `nginx` under `clusters/cluster-1/apps/app-rw` and `clusters/cluster-1/apps/app-rt` have a similar setup. To not go over nearly the same thing twice we are going to look at the `clusters/cluster-1/apps/app-rt` next, but as mentioned the full setup can be found in the [sample repository]().

<table>
<tr>
<th>Folder structure </th>
<th>`kustomization.yaml` of  </th>
</tr>
<tr>
<td>

<pre><code>
clusters/cluster-1
├── apps
│   ├── apps-rw
│   └── apps-rt
│       ├── kustomization.yaml
│       └── nginx
│           └── kustomization.yaml
└── infra
</code></pre>

</td>
<td>

<pre><code>
#clusters/cluster-1/apps/apps-rt/nginx/kustomization.yaml
resources:
  - ./../../../../../apps/nginx/nginx-rt
</code></pre>

> Note: fix relative path

</td>
</tr>
</table>

As shown above, the application resources referenced under `clusters/cluster-1/apps/apps-rt` are the resources we bundled up under `apps/nginx/nginx-rt` and should now only contain resources that can be changed in real-time.

And just like that you have separated all configurations to be managed by different controllers!

#### Real-time update of window times

We now only enable real-time and reconciliation window changes for the applications, which are defined under `apps`. By doing the same above steps with the `infra` folder, we could enable the reconciliation window times to be also changed in real-time .

### Set up `Kustomize` Controller.

Our GitOps repository is ready now, but how do we set up the `Kustomization` controller?
Let's first create a flux `Source` controller.

```sh
flux create source git source \
    --url="https://github.com/MahrRah/flux-maintanance-windows-sample" \
	  --username=<username>\
    --password=<PAT> \
    --branch=master \
    --interval=1m \
    --git-implementation=libgit2 \
    --silent
```

Next, we now need two controllers for apps and two for infra.
Replace therefore the `-<suffix>` once with `-rt` and once with `-rw`

```sh
flux create kustomization infra \
    --path="./clusters/edge-01/infra" \
    --source=source\
    --prune=true \
    --interval=1m
```

```sh
flux create kustomization apps-rt \
    --depends-on=infra \
    --path="./clusters/edge-01/apps/apps-<suffix>" \
    --source=source\
    --prune=true \
    --interval=1m
```

```sh
flux create kustomization apps-rw \
    --depends-on= apps-rt \
    --path="./clusters/edge-01/apps/apps-<suffix>" \
    --source=source\
    --prune=true \
    --interval=1m
```

Not this should give you something like this.

```sh
user@cluster:~$ flux get kustomization
NAME   	REVISION      	SUSPENDED	READY	MESSAGE
infra  	master/7cf3aaf	False    	True 	Applied revision: master/7cf3aaf
apps-rt	master/7cf3aaf	False    	True 	Applied revision: master/7cf3aaf
apps-rw	master/7cf3aaf	False    	True 	Applied revision: master/7cf3aaf
```

## Example

We have done all the hard work, lets's now use the sample to demonstrate the solution does what we expect.

Let us look at a scenario where we want to upgrade the `nginx` version and change the configuration `nginx.conf` to include the `nginx_status` endpoint.

The configuration we would like to be able to change in real-time.
But given the complexity of `nginx`, the upgrade should only happen between Monday and Thursday (I am just joking... but lets for the sake of this demo assume this upgrade has a high chance of a catastrophic production incident and you want your engineers to be there in case something goes worng)

### 1. Initial state

If we now navigate to the `http://<ip>:8080/` we should see somehing like this
![Index_of__.jpg](quiver-image-url/69B6992E30F69FAAE5E73351CB5D9690.jpg =816x217)

We can download the `nginx.conf` file and see what is currently mounted into the `nginx` pod from the confimap.

### 2. Change state

The next step is to change the state of our applicaion.
In the `deployment.yaml` we can change the image version number from `1.14.2` to the (currently) newest image `1.23.X`. And at the same time we can add the configuration to the `nginx.conf` to add the new enpoint. The endpoint will only be accessable after a pod restart, but we will still be able to see the config changes in the `nginx.conf` file.
In the server section add this location definition:

```conf
location /nginx_status {
                stub_status;
                allow all;	#only allow requests from localhost
            }
```

### 2. See real-time changes

Now if we go back to the browser and check the file `nginx.conf`, we should see the new section.

> Note: It might take up to 2 minutes in the worst case for the `Source` and then `Kustomize` Controler to reconcile

### 3. Wait till window opens and see effects.

If we now wait till the next reconciliation window opens, the pod should be restarted and we should be able to see the version either by chechecking the resouce.

```
kubectl describe pod  <nginx-podname> -n nginx
```

Or go to a non existing route in the browser and you should see it.
eg. navigate to `http://<ip>:8080/settings/`

## Conclusions

After this second part you should be good to go on using these reconciliation window and also have the knowlegde on how to customize your setup as much as you want :)
Hope it was helpfull and you can solve your problems when it comes to managing your resources with Flux.

---

_Image credit: K.Oh_
